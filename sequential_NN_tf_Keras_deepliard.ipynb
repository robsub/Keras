{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzt3N1U8FRrKgbitcb7+Fv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robsub/Keras/blob/main/sequential_NN_tf_Keras_deepliard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get (or create) and pre-process the data"
      ],
      "metadata": {
        "id": "5w4wdU-gSDGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "1N1YY0YrFchX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u9BFPl08ug3y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HXWcekcnEfC9"
      },
      "outputs": [],
      "source": [
        "# create lists to hold samples and labels\n",
        "\n",
        "train_labels = []\n",
        "train_samples = []"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example data:\n",
        "\n",
        "- An experimental drug was tested on individuals from ages 13 to 100 in a clinical trial. \n",
        "\n",
        "- The trial had 2100 participants. Half were under 65 years old, half were under 65 years or older. \n",
        "\n",
        "- Around 95% of patients 65 or older experienced side effects. \n",
        "\n",
        "- Around 95% of patients under 65% experienced no side effects. "
      ],
      "metadata": {
        "id": "WHpqlDb_GzLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "fit(\n",
        "    x=None,\n",
        "    y=None,\n",
        "    batch_size=None,\n",
        "    epochs=1,\n",
        "    verbose='auto',\n",
        "    callbacks=None,\n",
        "    validation_split=0.0,\n",
        "    validation_data=None,\n",
        "    shuffle=True,\n",
        "    class_weight=None,\n",
        "    sample_weight=None,\n",
        "    initial_epoch=0,\n",
        "    steps_per_epoch=None,\n",
        "    validation_steps=None,\n",
        "    validation_batch_size=None,\n",
        "    validation_freq=1,\n",
        "    max_queue_size=10,\n",
        "    workers=1,\n",
        "    use_multiprocessing=False\n",
        ")\n",
        "\n",
        "Trains the model for a fixed number of epochs (iterations on a dataset)."
      ],
      "metadata": {
        "id": "TBks0D5Vl6w_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Sequential X and Y lets use a numpy array (y must match x format)\n",
        "\n",
        "\n",
        "for i in range(50):\n",
        "# 5% younger individuals who did exp side effects\n",
        "  random_younger = randint(13,64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(1) # 1 = side effects\n",
        "\n",
        "# 5% older individuals who did not exp side effects\n",
        "  random_older = randint(65,100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(0) # 0 = no side effects\n",
        "\n",
        "for i in range(1000):\n",
        "# 95% younger individuals who did not exp side effects\n",
        "  random_younger = randint(13,64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(0)\n",
        "\n",
        "# 95% older individuals who did exp side effects\n",
        "  random_older = randint(65,100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(1)\n",
        "\n"
      ],
      "metadata": {
        "id": "e-BRT8yJSDla"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_samples[:5]: # print first 5 only\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aPFDGIcp-Fk",
        "outputId": "2fe6feb6-308c-4868-ed5b-cecf80f30b44"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39\n",
            "64\n",
            "23\n",
            "58\n",
            "71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_labels[:5]:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F96u8wPGxUA",
        "outputId": "72e5f6c3-c23b-40e1-c276-09cae3c77e63"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LEts process the data to be piped into something the fit command expects (lets go with a numpy array)\n",
        "\n",
        "train_labels = np.array(train_labels) # This line is converting the train_labels list to a numpy array. Numpy is a numerical computing library for Python and numpy.array() is a function that creates a new numpy array from a given list.\n",
        "train_samples = np.array(train_samples) # This line is converting the train_samples list to a numpy array.\n",
        "train_labels,train_samples = shuffle(train_labels, train_samples) # This line is shuffling the two numpy arrays train_labels and train_samples together using the shuffle() function from the sklearn.utils module. This is a common technique used in machine learning to randomize the order of the training data so that the model does not learn any order-related biases. The function returns two shuffled arrays, which are then unpacked and assigned to the original variable names train_labels and train_samples.\n",
        "\n",
        "# Check the type of the variables after conversion\n",
        "print(type(train_labels))   # Output: <class 'numpy.ndarray'>\n",
        "print(type(train_samples))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1UNp78Fp3-s",
        "outputId": "6ed57c10-afaf-43fa-92d3-101a5ec445e5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is scaling the train_samples data to normalize and standardize it, which is a common technique used in machine learning to improve model performance.\n",
        "\n",
        "The MinMaxScaler is a scaler object from the sklearn.preprocessing module that scales data to a specified range, which is [0,1] in this case. The feature_range parameter specifies the desired range.\n",
        "\n",
        "train_samples is reshaped to a 2D numpy array using the reshape() function with -1 as the first parameter and 1 as the second parameter. This is necessary because the fit_transform() method of MinMaxScaler expects a 2D array as input.\n",
        "\n",
        "The fit_transform() method of MinMaxScaler is then called on the reshaped train_samples data to fit the scaler to the data and transform it to the specified range. The resulting scaled data is assigned to the scaled_train_samples variable.\n",
        "\n",
        "AKA minmax scaler object used to create feature_range, feature range is then used on next line to rescale data from current range which is 13 to 100 down to a scale of 0 to 1. and the last bit ((train_samples.reshape(-1,1))) is changing data from 1 dimensional to 2 dimensional which is what is expected by the fit function. \n"
      ],
      "metadata": {
        "id": "kyy-c161Z35-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
      ],
      "metadata": {
        "id": "KEDPpaK7szXw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in scaled_train_samples[:5]:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySsJ5shCvrMy",
        "outputId": "10cf554a-f844-4b9d-d929-544dc75fc43a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.29885057]\n",
            "[0.5862069]\n",
            "[0.11494253]\n",
            "[0.51724138]\n",
            "[0.66666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple tf.keras Sequential Model"
      ],
      "metadata": {
        "id": "k-l_8CJ1yl84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf # to BUILD our first model\n",
        "from tensorflow import keras # to BUILD our first model\n",
        "from tensorflow.keras.models import Sequential # to BUILD our first model\n",
        "from tensorflow.keras.layers import Activation, Dense # to BUILD our first model\n",
        "from tensorflow.keras.optimizers import Adam # to TRAIN our first model\n",
        "from tensorflow.keras.metrics import categorical_crossentropy # to TRAIN our first model\n",
        "\n",
        "# tensorflow is an open-source software library for dataflow and differentiable programming across a range of tasks. It is commonly used for building deep learning models.\n",
        "# keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It is designed to enable fast experimentation with deep neural networks, and thus it is commonly used for building and training neural networks.\n",
        "# Sequential is a Keras class for creating a sequential neural network model.\n",
        "# Activation is a Keras class that specifies the activation function to be used in a neural network layer.\n",
        "# Dense is a Keras class that specifies a fully connected neural network layer.\n",
        "# Adam is a Keras class that specifies the optimizer used for training a neural network model.\n",
        "# categorical_crossentropy is a Keras metric used to calculate the loss of a classification model during training.\n",
        "# You will use these libraries and classes to define, compile, and train your neural network model for your specific machine learning task.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Je6eSvCryq84"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the sequential model (sequential is the simplest type of model using keras or tensorflow)\n",
        "# The sequential model architecture is a type of feedforward neural network, which means the information flows only in one direction, from input to output.\n",
        "# Yes, that is correct. Even though backpropagation propagates the error from right to left, a neural network model that consists of only forward-pass layers, like a Sequential model in Keras, is still considered a linear model because the output of each layer is fed directly into the next layer, without any recurrent connections that would allow feedback from later layers to earlier layers. Therefore, the model can be thought of as processing its input in a linear, sequential manner, one layer at a time, from left to right.\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(units=16, input_shape=(1,), activation='relu'), # hidden layer (not input layer)\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=2, activation='softmax'), # output layer\n",
        "])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UoVdo844Ios",
        "outputId": "bc8c3295-19aa-4fd2-8a4d-200d81d95e16"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 16)                32        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is defining a sequential model with three dense layers:\n",
        "\n",
        "The first dense layer has 16 units/neurons, and takes an input of shape (1,) (a single input value) and applies the rectified linear unit (ReLU) activation function.\n",
        "The second dense layer has 32 units/neurons and applies the ReLU activation function.\n",
        "The third dense layer has 2 units/neurons and applies the softmax activation function.\n",
        "The first dense layer is defined to have an input shape of (1,) because the input to the model will be a single value, and the output will be one of two classes. The final dense layer has 2 units/neurons because there are two classes to predict.\n",
        "\n",
        "So overall, the model takes a single input value and applies two hidden layers with ReLU activation, followed by a final output layer with a softmax activation to predict one of two classes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Rob Field\n",
        "What is a dense layer? What other types of layers exist and could be used in sequential NN?\n",
        "\n",
        "A dense layer is a type of layer in a neural network where each neuron is fully connected to all neurons in the previous layer. In a dense layer, each neuron computes a weighted sum of its inputs, adds a bias term, and applies an activation function to the result.\n",
        "\n",
        "Other types of layers that can be used in a sequential neural network include:\n",
        "\n",
        "Convolutional layers: these layers are used for image processing and feature extraction. They work by applying a convolution operation on the input, which is a sliding window that extracts features from the input.\n",
        "\n",
        "Pooling layers: these layers are used in conjunction with convolutional layers to reduce the dimensionality of the feature maps and provide translation invariance.\n",
        "\n",
        "Recurrent layers: these layers are used for processing sequential data, such as text or time series. They work by maintaining an internal state that is updated at each time step and can retain information from previous time steps.\n",
        "\n",
        "Dropout layers: these layers are used to prevent overfitting by randomly dropping out a fraction of the neurons during training.\n",
        "\n",
        "Batch normalization layers: these layers are used to normalize the inputs to each layer and speed up training by reducing the internal covariate shift.\n",
        "\n",
        "Embedding layers: these layers are used for natural language processing tasks, such as text classification or sentiment analysis. They work by mapping each word in the input text to a dense vector representation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "An activation function is a mathematical function applied to the output of a neural network layer. It introduces non-linearity into the model and allows it to learn more complex patterns.\n",
        "\n",
        "ReLU (Rectified Linear Unit) is a commonly used activation function in deep learning that returns 0 for negative inputs and the input value for non-negative inputs.\n",
        "\n",
        "Softmax is an activation function used in the final layer of a neural network to normalize the output into a probability distribution over multiple classes. It forces the sum of the output values to be equal to 1 and makes it easier to interpret the output as probabilities.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Rob Field\n",
        "When you say equal to 1, do you mean between 0 and 1?\n",
        "Yes, that's correct. The softmax function is used to convert the outputs of the neural network into a probability distribution, where each output is a number between 0 and 1, and the sum of all outputs is equal to 1.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Rob Field\n",
        "sum of all outputs is equal to 1. - can you explain?\n",
        "The softmax activation function transforms the output of a layer into a probability distribution over the predicted classes. The function takes in a vector of arbitrary real-valued scores and squashes them down to a range between 0 and 1, so that they can be interpreted as probabilities.\n",
        "\n",
        "The output of a softmax function is a vector of the same length as the input, where each element represents the probability of the input belonging to a particular class. The sum of all the elements in the output vector is always equal to 1, ensuring that the outputs can be interpreted as probabilities that an input belongs to each class.\n",
        "\n",
        "\n",
        "\n",
        "The input_shape parameter in Keras defines the shape of the input data that will be passed to the neural network model. In the example you provided, the input_shape is (1,), which means that the input data will have one dimension, and the size of that dimension is 1.\n",
        "\n",
        "In other words, the input data in this case will be a one-dimensional array with one element, such as [3] or [-2]. This is a common input shape for models that take in scalar values as inputs, such as regression models.\n",
        "\n",
        "Other possible input shapes that could be used depending on the data could be (n,) where n is the number of input features. For example, if the input data was a 2D array with 100 rows and 10 columns, the input shape could be (10,) to indicate that there are 10 features or (100, 10) to indicate there are 100 rows and 10 columns. The choice of input shape depends on the nature of the data and the type of problem being solved.\n"
      ],
      "metadata": {
        "id": "yIrIXRk1mteN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*italicized text*\n",
        "\n",
        ">Looking at a non sequntial model (BEYOND THE SCOPE OF THIS COURSE SO FAR):\n",
        "\n",
        ">here's an example code snippet that uses the functional API and connects layers together by passing the output of one layer as the input to the next layer AKA NOT a sequential/linear model\n",
        "\n",
        ">from tensorflow.keras.layers import Input, Dense\n",
        ">from tensorflow.keras.models import Model\n",
        "\n",
        "># Define the input layer\n",
        "input_layer = Input(shape=(784,))\n",
        "\n",
        "># Define the first hidden layer and connect it to the input layer\n",
        ">hidden_layer_1 = Dense(units=256, activation='relu')(input_layer)\n",
        "\n",
        ">layer\n",
        "hidden_layer_2 = Dense(units=128, activation='relu')(hidden_layer_1)\n",
        "\n",
        "># Define the output layer and connect it to the second hidden layer\n",
        "output_layer = Dense(units=10, activation='softmax')(hidden_layer_2)\n",
        "\n",
        "># Define the model using the input and output layers\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        ">This still looks linear to me (from left to right) where are the loops?\n",
        "\n",
        ">You're correct, the code I provided still shows a linear flow from right to left. However, with the functional API, you can create more complex models that involve loops or branches.\n",
        "\n",
        ">For example, you can create a loop by using a for loop to repeat a layer multiple times, or you can create a branch by connecting the output of one layer to multiple subsequent layers. These more complex models are often used for tasks such as image segmentation or language translation.\n",
        "\n",
        ">Here's an example of how you could create a simple loop using the functional API:\n",
        "\n",
        "scss\n",
        "Copy code\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "input_layer = Input(shape=(1,))\n",
        "hidden_layer = Dense(units=16, activation='relu')(input_layer)\n",
        "for i in range(3):\n",
        "    hidden_layer = Dense(units=16, activation='relu')(hidden_layer)\n",
        "output_layer = Dense(units=2, activation='softmax')(hidden_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "In this example, we use a for loop to create three hidden layers with the same architecture. The output of each hidden layer is connected to the next hidden layer in the loop, creating a loop in the model. The final output layer is connected to the last hidden layer in the loop. \n",
        "\n",
        "*italicized text*"
      ],
      "metadata": {
        "id": "W-hGk8gS-fnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the NN "
      ],
      "metadata": {
        "id": "ejlojJNAJnyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call model.compile function - prepares the model for training\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xl4RGofMJ3VD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, shuffle=True, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asyDngs5KUuR",
        "outputId": "465b0d16-0914-4043-c48c-f8e2cdfccc18"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "210/210 - 1s - loss: 0.3666 - accuracy: 0.8929 - 988ms/epoch - 5ms/step\n",
            "Epoch 2/30\n",
            "210/210 - 0s - loss: 0.3496 - accuracy: 0.8971 - 328ms/epoch - 2ms/step\n",
            "Epoch 3/30\n",
            "210/210 - 0s - loss: 0.3351 - accuracy: 0.9005 - 317ms/epoch - 2ms/step\n",
            "Epoch 4/30\n",
            "210/210 - 0s - loss: 0.3233 - accuracy: 0.9105 - 329ms/epoch - 2ms/step\n",
            "Epoch 5/30\n",
            "210/210 - 0s - loss: 0.3132 - accuracy: 0.9076 - 334ms/epoch - 2ms/step\n",
            "Epoch 6/30\n",
            "210/210 - 0s - loss: 0.3049 - accuracy: 0.9152 - 326ms/epoch - 2ms/step\n",
            "Epoch 7/30\n",
            "210/210 - 0s - loss: 0.2980 - accuracy: 0.9148 - 333ms/epoch - 2ms/step\n",
            "Epoch 8/30\n",
            "210/210 - 0s - loss: 0.2921 - accuracy: 0.9252 - 321ms/epoch - 2ms/step\n",
            "Epoch 9/30\n",
            "210/210 - 0s - loss: 0.2874 - accuracy: 0.9214 - 321ms/epoch - 2ms/step\n",
            "Epoch 10/30\n",
            "210/210 - 0s - loss: 0.2831 - accuracy: 0.9267 - 320ms/epoch - 2ms/step\n",
            "Epoch 11/30\n",
            "210/210 - 0s - loss: 0.2796 - accuracy: 0.9290 - 327ms/epoch - 2ms/step\n",
            "Epoch 12/30\n",
            "210/210 - 0s - loss: 0.2766 - accuracy: 0.9262 - 332ms/epoch - 2ms/step\n",
            "Epoch 13/30\n",
            "210/210 - 0s - loss: 0.2739 - accuracy: 0.9290 - 316ms/epoch - 2ms/step\n",
            "Epoch 14/30\n",
            "210/210 - 0s - loss: 0.2716 - accuracy: 0.9295 - 314ms/epoch - 1ms/step\n",
            "Epoch 15/30\n",
            "210/210 - 0s - loss: 0.2696 - accuracy: 0.9319 - 312ms/epoch - 1ms/step\n",
            "Epoch 16/30\n",
            "210/210 - 0s - loss: 0.2680 - accuracy: 0.9314 - 344ms/epoch - 2ms/step\n",
            "Epoch 17/30\n",
            "210/210 - 0s - loss: 0.2662 - accuracy: 0.9343 - 345ms/epoch - 2ms/step\n",
            "Epoch 18/30\n",
            "210/210 - 0s - loss: 0.2648 - accuracy: 0.9310 - 329ms/epoch - 2ms/step\n",
            "Epoch 19/30\n",
            "210/210 - 0s - loss: 0.2635 - accuracy: 0.9357 - 318ms/epoch - 2ms/step\n",
            "Epoch 20/30\n",
            "210/210 - 0s - loss: 0.2622 - accuracy: 0.9314 - 336ms/epoch - 2ms/step\n",
            "Epoch 21/30\n",
            "210/210 - 0s - loss: 0.2612 - accuracy: 0.9357 - 339ms/epoch - 2ms/step\n",
            "Epoch 22/30\n",
            "210/210 - 0s - loss: 0.2600 - accuracy: 0.9357 - 363ms/epoch - 2ms/step\n",
            "Epoch 23/30\n",
            "210/210 - 1s - loss: 0.2593 - accuracy: 0.9357 - 532ms/epoch - 3ms/step\n",
            "Epoch 24/30\n",
            "210/210 - 0s - loss: 0.2584 - accuracy: 0.9357 - 488ms/epoch - 2ms/step\n",
            "Epoch 25/30\n",
            "210/210 - 0s - loss: 0.2574 - accuracy: 0.9357 - 493ms/epoch - 2ms/step\n",
            "Epoch 26/30\n",
            "210/210 - 0s - loss: 0.2567 - accuracy: 0.9357 - 486ms/epoch - 2ms/step\n",
            "Epoch 27/30\n",
            "210/210 - 0s - loss: 0.2558 - accuracy: 0.9357 - 480ms/epoch - 2ms/step\n",
            "Epoch 28/30\n",
            "210/210 - 0s - loss: 0.2552 - accuracy: 0.9348 - 393ms/epoch - 2ms/step\n",
            "Epoch 29/30\n",
            "210/210 - 0s - loss: 0.2545 - accuracy: 0.9357 - 334ms/epoch - 2ms/step\n",
            "Epoch 30/30\n",
            "210/210 - 0s - loss: 0.2538 - accuracy: 0.9371 - 315ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f46341ff7c0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is being cached to cause the first epoch to take 6ms and the rest 2ms (the first time round - changed since writing this)? Presumably, something is being cached? Do you know what is? AKA What does the epoch need to do only once on the first epoch?\n",
        "\n",
        "The time taken to complete an epoch in a neural network model can depend on several factors such as the size of the dataset, the complexity of the model, and the computing resources available.\n",
        "\n",
        "In this case, it is possible that the first epoch took longer because the data needed to be loaded into the cache or memory. The subsequent epochs may have taken less time because the data was already loaded into the cache or memory and did not need to be reloaded. This can result in faster processing times for the subsequent epochs.\n",
        "\n",
        "Additionally, the Keras fit() function can perform various initialization steps before the first epoch, such as compiling the model and initializing the optimizer, which may also contribute to the longer execution time for the first epoch.\n",
        "\n",
        "It's worth noting that the differences in execution time between epochs in this example are relatively small, and it's unlikely to have a significant impact on the overall training time.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Rob Field\n",
        "I can see that the accuracy improves on each epoch. This makes sense, but does the accuracy always increase per epoch? or is it because this is a simple dataset and model?\n",
        "\n",
        "The accuracy of a model on a given dataset can increase, decrease or remain unchanged from one epoch to the next. The direction and rate of change in accuracy can depend on various factors, such as the complexity of the model, the size and quality of the training dataset, the choice of optimizer and learning rate, and the stopping criterion used to terminate the training process.\n",
        "\n",
        "In general, when a model is underfitting the data, the accuracy is likely to increase with each epoch as the model adjusts its parameters to better fit the training data. However, when the model starts to overfit the data, the accuracy on the training dataset may continue to improve, but the accuracy on the validation dataset may start to decrease, indicating that the model is no longer generalizing well to new data.\n",
        "\n",
        "In the case of the code snippet you provided, the accuracy is increasing on each epoch, which suggests that the model is improving its ability to fit the training data. However, it's also possible that this is due to the simplicity of the dataset and the model. In more complex scenarios, the accuracy may not increase on every epoch or may plateau at some point, indicating that the model has reached its optimal performance."
      ],
      "metadata": {
        "id": "ZJymVEnvL65D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdqgeYdMKvBv",
        "outputId": "2bbbca27-b134-4564-ec80-cfe33c65a142"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 16)                32        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Validation Set With TensorFlow's Keras API"
      ],
      "metadata": {
        "id": "p6a877zRRqjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CGPT\n",
        "In machine learning, a validation set is a portion of the dataset used to evaluate the performance of a model during training. In the context of sequential neural networks using Keras, the validation set is typically used to evaluate the model's performance on data that it has not seen before.\n",
        "\n",
        "During the training process, the model is typically trained on a portion of the dataset called the training set. The model's performance on the training set is used to adjust its weights and improve its accuracy. However, to ensure that the model is not overfitting (i.e., performing well on the training set but poorly on new, unseen data), it is important to evaluate the model's performance on a separate dataset that it has not been trained on. This is where the validation set comes in.\n",
        "\n",
        "In Keras, you can specify a validation set by passing the validation_data argument to the fit() function. The validation_data argument takes a tuple of inputs and targets (e.g., (x_val, y_val)), which represent the validation data. During training, Keras will evaluate the model's performance on the validation data at the end of each epoch, and this information can be used to monitor the model's progress and adjust its hyperparameters (e.g., learning rate, batch size, etc.) to improve its accuracy."
      ],
      "metadata": {
        "id": "NBceA0qOTOG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://deeplizard.com/learn/video/dzoh8cfnvnI\n",
        "\n",
        "Creating A Validation Set\n",
        "There are **two ways** to create a validation set to use with a tf.keras.Sequential model.\n",
        "\n",
        "Manually Create Validation Set\n",
        "The first way is to create a data structure to hold a validation set, and place data directly in that structure in the same nature we did for the training set.\n",
        "\n",
        "This data structure should be a tuple valid_set = (x_val, y_val) of Numpy arrays or tensors, where x_val is a numpy array or tensor containing validation samples, and y_val is a numpy array or tensor containing validation labels.\n",
        "\n",
        "When we call model.fit(), we would pass in the validation set in addition to the training set. We pass the validation set by specifying the validation_data parameter.\n",
        "\n",
        "model.fit(\n",
        "      x=scaled_train_samples\n",
        "    , y=train_labels\n",
        "    , validation_data=valid_set\n",
        "    , batch_size=10\n",
        "    , epochs=30\n",
        "    , verbose=2\n",
        ")\n",
        "When the model trains, it would continue to train only on the training set, but additionally, it would also be evaluating the validation set.\n",
        "\n",
        "Create Validation Set With Keras\n",
        "There is another way to create a validation set, and it saves a step!\n",
        "\n",
        "If we don't already have a specified validation set created, then when we call model.fit(), we can set a value for the validation_split parameter. It expects a fractional number between 0 and 1. Suppose that we set this parameter to 0.1.\n",
        "\n",
        "model.fit(\n",
        "      x=scaled_train_samples\n",
        "    , y=train_labels\n",
        "    , validation_split=0.1\n",
        "    , batch_size=10\n",
        "    , epochs=30\n",
        "    , verbose=2\n",
        ")\n",
        "With this parameter specified, Keras will split apart a fraction (10% in this example) of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch.\n",
        "\n",
        "Note that the fit() function shuffles the data before each epoch by default. When specifying the validation_split parameter, however, the validation data is selected from the last samples in the x and y data before shuffling.\n",
        "\n",
        "Therefore, in the case we're using validation_split in this way to create our validation data, we need to be sure that our data has been shuffled ahead of time, like we previously did in an earlier episode.\n",
        "\n",
        "Interpret Validation Metrics\n",
        "Now, regardless of which method we use to create validation data, when we call model.fit(), then in addition to loss and accuracy being displayed for each epoch as we saw last time, we will now also see val_loss and val_acc to track the loss and accuracy on the validation set."
      ],
      "metadata": {
        "id": "83nCM9f4W6oQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Validation Set With Keras "
      ],
      "metadata": {
        "id": "JqSwyraDXKLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=scaled_train_samples, y=train_labels, validation_split=0.1, batch_size=10, epochs=30, shuffle=True, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-66GoV_-MQFW",
        "outputId": "a406ece7-b744-45d9-c31a-ed3b3ef10de6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "189/189 - 1s - loss: 0.2585 - accuracy: 0.9344 - val_loss: 0.2074 - val_accuracy: 0.9476 - 566ms/epoch - 3ms/step\n",
            "Epoch 2/30\n",
            "189/189 - 0s - loss: 0.2579 - accuracy: 0.9354 - val_loss: 0.2071 - val_accuracy: 0.9476 - 323ms/epoch - 2ms/step\n",
            "Epoch 3/30\n",
            "189/189 - 0s - loss: 0.2575 - accuracy: 0.9381 - val_loss: 0.2074 - val_accuracy: 0.9571 - 362ms/epoch - 2ms/step\n",
            "Epoch 4/30\n",
            "189/189 - 0s - loss: 0.2568 - accuracy: 0.9402 - val_loss: 0.2061 - val_accuracy: 0.9476 - 407ms/epoch - 2ms/step\n",
            "Epoch 5/30\n",
            "189/189 - 0s - loss: 0.2564 - accuracy: 0.9376 - val_loss: 0.2053 - val_accuracy: 0.9476 - 403ms/epoch - 2ms/step\n",
            "Epoch 6/30\n",
            "189/189 - 0s - loss: 0.2559 - accuracy: 0.9392 - val_loss: 0.2055 - val_accuracy: 0.9476 - 337ms/epoch - 2ms/step\n",
            "Epoch 7/30\n",
            "189/189 - 1s - loss: 0.2555 - accuracy: 0.9354 - val_loss: 0.2052 - val_accuracy: 0.9476 - 558ms/epoch - 3ms/step\n",
            "Epoch 8/30\n",
            "189/189 - 1s - loss: 0.2551 - accuracy: 0.9349 - val_loss: 0.2052 - val_accuracy: 0.9571 - 526ms/epoch - 3ms/step\n",
            "Epoch 9/30\n",
            "189/189 - 1s - loss: 0.2549 - accuracy: 0.9381 - val_loss: 0.2054 - val_accuracy: 0.9571 - 583ms/epoch - 3ms/step\n",
            "Epoch 10/30\n",
            "189/189 - 1s - loss: 0.2543 - accuracy: 0.9413 - val_loss: 0.2049 - val_accuracy: 0.9571 - 556ms/epoch - 3ms/step\n",
            "Epoch 11/30\n",
            "189/189 - 1s - loss: 0.2539 - accuracy: 0.9413 - val_loss: 0.2045 - val_accuracy: 0.9571 - 507ms/epoch - 3ms/step\n",
            "Epoch 12/30\n",
            "189/189 - 0s - loss: 0.2535 - accuracy: 0.9413 - val_loss: 0.2039 - val_accuracy: 0.9571 - 350ms/epoch - 2ms/step\n",
            "Epoch 13/30\n",
            "189/189 - 0s - loss: 0.2532 - accuracy: 0.9376 - val_loss: 0.2037 - val_accuracy: 0.9571 - 363ms/epoch - 2ms/step\n",
            "Epoch 14/30\n",
            "189/189 - 0s - loss: 0.2526 - accuracy: 0.9370 - val_loss: 0.2045 - val_accuracy: 0.9571 - 348ms/epoch - 2ms/step\n",
            "Epoch 15/30\n",
            "189/189 - 0s - loss: 0.2524 - accuracy: 0.9413 - val_loss: 0.2030 - val_accuracy: 0.9571 - 380ms/epoch - 2ms/step\n",
            "Epoch 16/30\n",
            "189/189 - 0s - loss: 0.2520 - accuracy: 0.9365 - val_loss: 0.2041 - val_accuracy: 0.9571 - 362ms/epoch - 2ms/step\n",
            "Epoch 17/30\n",
            "189/189 - 0s - loss: 0.2517 - accuracy: 0.9423 - val_loss: 0.2022 - val_accuracy: 0.9476 - 405ms/epoch - 2ms/step\n",
            "Epoch 18/30\n",
            "189/189 - 0s - loss: 0.2516 - accuracy: 0.9392 - val_loss: 0.2023 - val_accuracy: 0.9571 - 391ms/epoch - 2ms/step\n",
            "Epoch 19/30\n",
            "189/189 - 0s - loss: 0.2512 - accuracy: 0.9407 - val_loss: 0.2021 - val_accuracy: 0.9571 - 355ms/epoch - 2ms/step\n",
            "Epoch 20/30\n",
            "189/189 - 0s - loss: 0.2508 - accuracy: 0.9381 - val_loss: 0.2024 - val_accuracy: 0.9571 - 392ms/epoch - 2ms/step\n",
            "Epoch 21/30\n",
            "189/189 - 0s - loss: 0.2505 - accuracy: 0.9413 - val_loss: 0.2014 - val_accuracy: 0.9571 - 363ms/epoch - 2ms/step\n",
            "Epoch 22/30\n",
            "189/189 - 0s - loss: 0.2503 - accuracy: 0.9413 - val_loss: 0.2009 - val_accuracy: 0.9571 - 344ms/epoch - 2ms/step\n",
            "Epoch 23/30\n",
            "189/189 - 0s - loss: 0.2500 - accuracy: 0.9392 - val_loss: 0.2018 - val_accuracy: 0.9571 - 344ms/epoch - 2ms/step\n",
            "Epoch 24/30\n",
            "189/189 - 0s - loss: 0.2497 - accuracy: 0.9413 - val_loss: 0.2014 - val_accuracy: 0.9571 - 368ms/epoch - 2ms/step\n",
            "Epoch 25/30\n",
            "189/189 - 0s - loss: 0.2496 - accuracy: 0.9402 - val_loss: 0.2010 - val_accuracy: 0.9571 - 387ms/epoch - 2ms/step\n",
            "Epoch 26/30\n",
            "189/189 - 0s - loss: 0.2494 - accuracy: 0.9413 - val_loss: 0.2013 - val_accuracy: 0.9571 - 356ms/epoch - 2ms/step\n",
            "Epoch 27/30\n",
            "189/189 - 0s - loss: 0.2490 - accuracy: 0.9413 - val_loss: 0.2004 - val_accuracy: 0.9571 - 340ms/epoch - 2ms/step\n",
            "Epoch 28/30\n",
            "189/189 - 0s - loss: 0.2487 - accuracy: 0.9413 - val_loss: 0.2001 - val_accuracy: 0.9571 - 368ms/epoch - 2ms/step\n",
            "Epoch 29/30\n",
            "189/189 - 0s - loss: 0.2483 - accuracy: 0.9381 - val_loss: 0.2005 - val_accuracy: 0.9571 - 383ms/epoch - 2ms/step\n",
            "Epoch 30/30\n",
            "189/189 - 0s - loss: 0.2482 - accuracy: 0.9413 - val_loss: 0.1996 - val_accuracy: 0.9571 - 371ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f46376f24f0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this parameter specified, Keras will split apart a fraction (10% in this example) of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch.\n",
        "\n",
        "Note that the fit() function shuffles the data before each epoch by default. When specifying the validation_split parameter, however, the validation data is selected from the last samples in the x and y data before shuffling.\n",
        "\n",
        "Therefore, in the case we're using validation_split in this way to create our validation data, we need to **be sure that our data has been shuffled ahead of time, like we previously did in an earlier episode.**"
      ],
      "metadata": {
        "id": "TRp17_28Yqdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpret Validation Metrics\n",
        "Now, regardless of which method we use to create validation data, when we call model.fit(), then in addition to loss and accuracy being displayed for each epoch as we saw last time, we will now also see val_loss and val_acc to track the loss and accuracy on the validation set.\n",
        "\n",
        "We can now see not only how well our model is learning the features of the training data, but also how well the model is generalizing to new, unseen data from the validation set (so no overfitting, which is good). Next, we'll see how to use our model for inference.\n",
        "\n",
        "CGPTOverfitting occurs when a machine learning model becomes too complex and starts to fit the noise in the training data rather than the underlying patterns in the data. This leads to poor generalization performance on new, unseen data, as the model is too specific to the training data and does not capture the underlying patterns that are common across the data."
      ],
      "metadata": {
        "id": "SRWxR9pvY7Dw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Predictions with TensorFlow's Keras API (use our model for inference)\n",
        "\n",
        "In this episode, we'll demonstrate how to use a neural network for inference to make predictions on data from a test set. We'll continue working with the same tf.keras.Sequential model and data that we've used in the last few episodes to do so.\n",
        "\n",
        "\n",
        "As we touched on previously, when we train a model, the hope is that we'll later be able to take the trained model, apply it to new data, and have the model generalize and accurately predict on data it hasn't seen before.\n",
        "\n",
        "For example, suppose we have a model that categorizes images of cats or dogs and that the training data contained thousands of images of cats and dogs from a particular data set online.\n",
        "\n",
        "What Is Inference?\n",
        "Now suppose that later we want to take this model and use it to predict on other images of cats and dogs from a different data set. The hope is that, even though our model wasn't exposed to these particular dog and cat images during training, it will still be able to accurately make predictions for them based on what it's learned from the cat and dog data set from which it was trained.\n",
        "\n",
        "We call this process inference, as the model is using its knowledge gained from training and using it to infer a prediction or result.\n",
        "\n",
        "At this point, the model we've been working with over the past few episodes has now been trained and validated. Given the results we've seen from the validation data, it appears that this model should do well on predicting on a new test set.\n",
        "\n",
        "Note that the test set is the set of data used specifically for inference after training has concluded. You can find more information on all the different types of data sets used in deep learning in the Deep Learning Fundamentals course."
      ],
      "metadata": {
        "id": "p_pdz6RHZmXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating The Test Set\n",
        "We'll create a test set in the same fashion for which we created the training set. In general, the test set should always be processed in the same way as the training set.\n",
        "\n",
        "We won't go step-by-step over the code that generates and processes the test data below, as it has already been covered in detail in an earlier episode where we generated the training data, but be sure you have all the imports in place from the previous episodes, as well as all of the existing code up to this point.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZAFvDnZSk574"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels =  []\n",
        "test_samples = []\n",
        "\n",
        "for i in range(10):\n",
        "    # The 5% of younger individuals who did experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    test_samples.append(random_younger)\n",
        "    test_labels.append(1)\n",
        "\n",
        "    # The 5% of older individuals who did not experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    test_samples.append(random_older)\n",
        "    test_labels.append(0)\n",
        "\n",
        "for i in range(200):\n",
        "    # The 95% of younger individuals who did not experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    test_samples.append(random_younger)\n",
        "    test_labels.append(0)\n",
        "\n",
        "    # The 95% of older individuals who did experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    test_samples.append(random_older)\n",
        "    test_labels.append(1)\n",
        "\n",
        "test_labels = np.array(test_labels)\n",
        "test_samples = np.array(test_samples)\n",
        "test_labels, test_samples = shuffle(test_labels, test_samples)\n",
        "\n",
        "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))"
      ],
      "metadata": {
        "id": "5qNJwflOlbwm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict (on the test data)\n",
        "\n",
        "To get predictions from the model for the test set, we call model.predict()."
      ],
      "metadata": {
        "id": "XXXW_Ow4loq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(\n",
        "      x=scaled_test_samples\n",
        "    , batch_size=10\n",
        "    , verbose=0\n",
        ")"
      ],
      "metadata": {
        "id": "WKfO3rPmluPZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To this function, we pass in the test samples x, specify a batch_size, and specify which level of verbosity we want from log messages during prediction generation. The output from the predictions won't be relevant for us, so we're setting verbose=0 for no output.\n",
        "\n",
        "Note that, unlike with training and validation sets, we do not pass the labels of the test set to the model during the inference stage.\n",
        "\n",
        "To see what the model's predictions look like, we can iterate over them and print them out."
      ],
      "metadata": {
        "id": "SqQzDOa6l5FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in predictions:\n",
        "    print(i)\n",
        "                #  0          1           test_labels.append(0)     test_labels.append(1)\n",
        "    # Output eg: [0.9188097  0.08119021] - model is assigning a 92% probability of this patient not exp a side effect and around 8% probability of this patient exp a side effect. \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_syMijUpl8Fl",
        "outputId": "a7bb0d1d-2ff6-4451-eda2-4f9ee5b68f04"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9188097  0.08119021]\n",
            "[0.03614618 0.9638539 ]\n",
            "[0.27526   0.7247401]\n",
            "[0.02743222 0.9725678 ]\n",
            "[0.3187455 0.6812545]\n",
            "[0.9698119  0.03018805]\n",
            "[0.0207737  0.97922635]\n",
            "[0.9761416  0.02385842]\n",
            "[0.9747692  0.02523084]\n",
            "[0.9660294  0.03397056]\n",
            "[0.9754777  0.02452233]\n",
            "[0.97252196 0.02747807]\n",
            "[0.9760652 0.0239347]\n",
            "[0.9679746  0.03202535]\n",
            "[0.93254644 0.0674535 ]\n",
            "[0.10498349 0.8950165 ]\n",
            "[0.7901769  0.20982301]\n",
            "[0.9761263  0.02387366]\n",
            "[0.9747692  0.02523084]\n",
            "[0.9639705  0.03602953]\n",
            "[0.16885583 0.83114403]\n",
            "[0.46657914 0.5334208 ]\n",
            "[0.16885583 0.83114403]\n",
            "[0.03297994 0.96702003]\n",
            "[0.97404075 0.02595928]\n",
            "[0.97611105 0.0238889 ]\n",
            "[0.9679746  0.03202535]\n",
            "[0.97252196 0.02747807]\n",
            "[0.07420922 0.9257908 ]\n",
            "[0.9760271  0.02397294]\n",
            "[0.9761263  0.02387366]\n",
            "[0.06217197 0.93782794]\n",
            "[0.93254644 0.0674535 ]\n",
            "[0.9760652 0.0239347]\n",
            "[0.97609586 0.02390416]\n",
            "[0.05686053 0.9431395 ]\n",
            "[0.97610337 0.02389652]\n",
            "[0.97610337 0.02389652]\n",
            "[0.16885585 0.83114415]\n",
            "[0.10498349 0.89501643]\n",
            "[0.9554852  0.04451472]\n",
            "[0.0207737  0.97922635]\n",
            "[0.9435679  0.05643217]\n",
            "[0.9760194 0.0239806]\n",
            "[0.8226706  0.17732944]\n",
            "[0.9760652 0.0239347]\n",
            "[0.014303   0.98569703]\n",
            "[0.93254644 0.0674535 ]\n",
            "[0.9761111 0.0238889]\n",
            "[0.9761111 0.0238889]\n",
            "[0.97173053 0.02826952]\n",
            "[0.9435679  0.05643217]\n",
            "[0.71277213 0.287228  ]\n",
            "[0.97611105 0.0238889 ]\n",
            "[0.3187455 0.6812545]\n",
            "[0.36563474 0.6343653 ]\n",
            "[0.05197766 0.9480223 ]\n",
            "[0.01892758 0.9810724 ]\n",
            "[0.01185849 0.98814154]\n",
            "[0.09631068 0.9036893 ]\n",
            "[0.96171534 0.0382847 ]\n",
            "[0.96171534 0.0382847 ]\n",
            "[0.12462534 0.87537456]\n",
            "[0.07420922 0.9257907 ]\n",
            "[0.13558072 0.86441916]\n",
            "[0.0227957  0.97720426]\n",
            "[0.9732919  0.02670818]\n",
            "[0.36563474 0.6343653 ]\n",
            "[0.02743222 0.97256774]\n",
            "[0.9261135  0.07388657]\n",
            "[0.047493 0.952507]\n",
            "[0.97404075 0.02595928]\n",
            "[0.13558072 0.86441916]\n",
            "[0.4152179 0.5847821]\n",
            "[0.9760806  0.02391943]\n",
            "[0.12462534 0.87537456]\n",
            "[0.01570528 0.9842946 ]\n",
            "[0.9435679  0.05643217]\n",
            "[0.0207737  0.97922635]\n",
            "[0.03614617 0.96385384]\n",
            "[0.03614618 0.9638539 ]\n",
            "[0.0227957  0.97720426]\n",
            "[0.0207737  0.97922635]\n",
            "[0.01185849 0.98814154]\n",
            "[0.97605    0.02394999]\n",
            "[0.9760575  0.02394235]\n",
            "[0.10498349 0.8950165 ]\n",
            "[0.9760194 0.0239806]\n",
            "[0.02743222 0.97256774]\n",
            "[0.01570528 0.98429465]\n",
            "[0.03008241 0.96991765]\n",
            "[0.8226706  0.17732944]\n",
            "[0.12462534 0.87537456]\n",
            "[0.01724264 0.9827573 ]\n",
            "[0.0207737  0.97922635]\n",
            "[0.36563474 0.6343653 ]\n",
            "[0.047493 0.952507]\n",
            "[0.27526   0.7247401]\n",
            "[0.9754777  0.02452232]\n",
            "[0.3187455 0.6812545]\n",
            "[0.27526   0.7247401]\n",
            "[0.05686053 0.9431395 ]\n",
            "[0.01570528 0.9842946 ]\n",
            "[0.4152179 0.5847821]\n",
            "[0.97173053 0.02826952]\n",
            "[0.08100211 0.9189979 ]\n",
            "[0.62052524 0.3794747 ]\n",
            "[0.04337757 0.9566224 ]\n",
            "[0.97252196 0.02747807]\n",
            "[0.01185849 0.98814154]\n",
            "[0.23565485 0.76434517]\n",
            "[0.01892758 0.9810724 ]\n",
            "[0.03614618 0.9638539 ]\n",
            "[0.9760652 0.0239347]\n",
            "[0.03960393 0.96039605]\n",
            "[0.6682615  0.33173853]\n",
            "[0.9760194 0.0239806]\n",
            "[0.9732919  0.02670818]\n",
            "[0.12462535 0.8753746 ]\n",
            "[0.95190203 0.04809801]\n",
            "[0.9261135  0.07388657]\n",
            "[0.13558072 0.86441916]\n",
            "[0.8226706  0.17732944]\n",
            "[0.9660294  0.03397056]\n",
            "[0.36563474 0.6343653 ]\n",
            "[0.97611105 0.0238889 ]\n",
            "[0.9083375  0.09166253]\n",
            "[0.05197766 0.9480223 ]\n",
            "[0.4665792  0.53342086]\n",
            "[0.05686053 0.9431395 ]\n",
            "[0.01570528 0.9842946 ]\n",
            "[0.08835743 0.9116426 ]\n",
            "[0.11443797 0.88556206]\n",
            "[0.9679746  0.03202535]\n",
            "[0.970917   0.02908306]\n",
            "[0.05686053 0.9431395 ]\n",
            "[0.9760575  0.02394235]\n",
            "[0.07420922 0.9257907 ]\n",
            "[0.9717305  0.02826952]\n",
            "[0.08835743 0.9116426 ]\n",
            "[0.970917   0.02908306]\n",
            "[0.5703365  0.42966345]\n",
            "[0.20017457 0.7998254 ]\n",
            "[0.9761263  0.02387366]\n",
            "[0.27526   0.7247401]\n",
            "[0.16885583 0.83114403]\n",
            "[0.27526   0.7247401]\n",
            "[0.97173053 0.02826952]\n",
            "[0.9760576  0.02394235]\n",
            "[0.01724264 0.98275733]\n",
            "[0.08835743 0.9116426 ]\n",
            "[0.97614914 0.0238508 ]\n",
            "[0.02743222 0.9725678 ]\n",
            "[0.62052524 0.3794747 ]\n",
            "[0.02743222 0.9725678 ]\n",
            "[0.36563474 0.6343653 ]\n",
            "[0.9660294  0.03397056]\n",
            "[0.95881313 0.04118685]\n",
            "[0.014303   0.98569703]\n",
            "[0.9480444  0.05195563]\n",
            "[0.047493 0.952507]\n",
            "[0.01892758 0.9810724 ]\n",
            "[0.03614618 0.9638539 ]\n",
            "[0.3187455 0.6812545]\n",
            "[0.96397054 0.03602953]\n",
            "[0.05197766 0.9480223 ]\n",
            "[0.71277213 0.287228  ]\n",
            "[0.10498349 0.8950165 ]\n",
            "[0.9261135  0.07388657]\n",
            "[0.790177   0.20982304]\n",
            "[0.9760652 0.0239347]\n",
            "[0.93254644 0.0674535 ]\n",
            "[0.97611105 0.0238889 ]\n",
            "[0.0207737  0.97922635]\n",
            "[0.06217197 0.93782794]\n",
            "[0.01892758 0.9810724 ]\n",
            "[0.01570528 0.9842946 ]\n",
            "[0.9083375  0.09166253]\n",
            "[0.96797466 0.03202535]\n",
            "[0.05686053 0.9431395 ]\n",
            "[0.85108054 0.14891963]\n",
            "[0.8226706  0.17732944]\n",
            "[0.08835743 0.9116426 ]\n",
            "[0.03008241 0.96991765]\n",
            "[0.97173053 0.02826952]\n",
            "[0.4152179 0.5847821]\n",
            "[0.96397054 0.03602953]\n",
            "[0.95881313 0.04118685]\n",
            "[0.4665792  0.53342086]\n",
            "[0.9761111 0.0238889]\n",
            "[0.9435679  0.05643217]\n",
            "[0.01570528 0.9842946 ]\n",
            "[0.9761416  0.02385842]\n",
            "[0.0207737  0.97922635]\n",
            "[0.0227957  0.97720426]\n",
            "[0.9747691  0.02523084]\n",
            "[0.03614618 0.9638539 ]\n",
            "[0.5703365  0.42966345]\n",
            "[0.01724264 0.98275733]\n",
            "[0.97608817 0.02391179]\n",
            "[0.6682615  0.33173853]\n",
            "[0.97609586 0.02390416]\n",
            "[0.27526   0.7247401]\n",
            "[0.04337757 0.9566224 ]\n",
            "[0.08835743 0.9116426 ]\n",
            "[0.06794389 0.93205607]\n",
            "[0.97614914 0.0238508 ]\n",
            "[0.01570528 0.9842946 ]\n",
            "[0.9325465 0.0674535]\n",
            "[0.02743222 0.97256774]\n",
            "[0.8226706  0.17732944]\n",
            "[0.9760194 0.0239806]\n",
            "[0.9679746  0.03202535]\n",
            "[0.08835743 0.9116426 ]\n",
            "[0.9698119  0.03018805]\n",
            "[0.9760194 0.0239806]\n",
            "[0.03297994 0.96702003]\n",
            "[0.7901769  0.20982301]\n",
            "[0.97613394 0.02386603]\n",
            "[0.06217198 0.937828  ]\n",
            "[0.9554852  0.04451472]\n",
            "[0.6682615  0.33173853]\n",
            "[0.71277213 0.287228  ]\n",
            "[0.9760271  0.02397294]\n",
            "[0.9679746  0.03202535]\n",
            "[0.14733715 0.85266286]\n",
            "[0.85108054 0.14891963]\n",
            "[0.12462534 0.87537456]\n",
            "[0.014303   0.98569703]\n",
            "[0.014303   0.98569703]\n",
            "[0.16885583 0.83114403]\n",
            "[0.94804436 0.05195563]\n",
            "[0.047493 0.952507]\n",
            "[0.05686053 0.9431395 ]\n",
            "[0.14733715 0.85266286]\n",
            "[0.97608817 0.02391179]\n",
            "[0.97603464 0.02396528]\n",
            "[0.970917   0.02908306]\n",
            "[0.12462535 0.8753746 ]\n",
            "[0.10498349 0.89501643]\n",
            "[0.16885583 0.83114403]\n",
            "[0.85108054 0.14891963]\n",
            "[0.5703365  0.42966345]\n",
            "[0.01892758 0.9810724 ]\n",
            "[0.03960393 0.96039605]\n",
            "[0.14733715 0.85266286]\n",
            "[0.97608817 0.02391179]\n",
            "[0.9760729  0.02392706]\n",
            "[0.01570528 0.98429465]\n",
            "[0.12462535 0.8753746 ]\n",
            "[0.9760806  0.02391943]\n",
            "[0.05197766 0.9480223 ]\n",
            "[0.01570528 0.9842946 ]\n",
            "[0.46657914 0.5334208 ]\n",
            "[0.12462534 0.87537456]\n",
            "[0.7535134  0.24648654]\n",
            "[0.13558072 0.86441916]\n",
            "[0.12462534 0.87537456]\n",
            "[0.97605    0.02394999]\n",
            "[0.8756268  0.12437317]\n",
            "[0.96397054 0.03602953]\n",
            "[0.97404075 0.02595928]\n",
            "[0.9760575  0.02394235]\n",
            "[0.7535134  0.24648654]\n",
            "[0.0207737  0.97922635]\n",
            "[0.0227957  0.97720426]\n",
            "[0.95190203 0.04809801]\n",
            "[0.01570528 0.9842946 ]\n",
            "[0.97609586 0.02390416]\n",
            "[0.11443797 0.88556206]\n",
            "[0.9760271  0.02397294]\n",
            "[0.05197766 0.9480223 ]\n",
            "[0.93254644 0.0674535 ]\n",
            "[0.9747691  0.02523084]\n",
            "[0.9760575  0.02394235]\n",
            "[0.85108054 0.14891963]\n",
            "[0.03008241 0.96991765]\n",
            "[0.8756268  0.12437317]\n",
            "[0.5186591  0.48134083]\n",
            "[0.08835743 0.9116426 ]\n",
            "[0.11443797 0.88556206]\n",
            "[0.03960393 0.96039605]\n",
            "[0.36563474 0.6343653 ]\n",
            "[0.23565485 0.76434517]\n",
            "[0.9760729  0.02392706]\n",
            "[0.01570528 0.9842946 ]\n",
            "[0.01185849 0.98814154]\n",
            "[0.13558072 0.86441916]\n",
            "[0.05197766 0.94802237]\n",
            "[0.11443797 0.88556206]\n",
            "[0.02743222 0.9725678 ]\n",
            "[0.9188097  0.08119021]\n",
            "[0.97609586 0.02390416]\n",
            "[0.01724264 0.9827573 ]\n",
            "[0.10498349 0.8950165 ]\n",
            "[0.9760729  0.02392706]\n",
            "[0.27526   0.7247401]\n",
            "[0.5703365  0.42966345]\n",
            "[0.9754777  0.02452232]\n",
            "[0.8510804 0.1489196]\n",
            "[0.0207737  0.97922635]\n",
            "[0.01724264 0.9827573 ]\n",
            "[0.09631068 0.90368927]\n",
            "[0.97604245 0.02395764]\n",
            "[0.9554852  0.04451472]\n",
            "[0.27526   0.7247401]\n",
            "[0.03960393 0.96039605]\n",
            "[0.03008241 0.96991765]\n",
            "[0.9732919  0.02670818]\n",
            "[0.10498349 0.89501643]\n",
            "[0.02500949 0.9749905 ]\n",
            "[0.9761339  0.02386603]\n",
            "[0.08100211 0.9189979 ]\n",
            "[0.9760729  0.02392706]\n",
            "[0.5703365  0.42966345]\n",
            "[0.97252196 0.02747807]\n",
            "[0.16885583 0.83114403]\n",
            "[0.27526   0.7247401]\n",
            "[0.05686053 0.9431395 ]\n",
            "[0.02500949 0.97499055]\n",
            "[0.9083375  0.09166253]\n",
            "[0.9761339  0.02386603]\n",
            "[0.9698119  0.03018805]\n",
            "[0.9761263  0.02387366]\n",
            "[0.03297994 0.96702003]\n",
            "[0.97173053 0.02826952]\n",
            "[0.07420922 0.9257907 ]\n",
            "[0.0227957  0.97720426]\n",
            "[0.9754777  0.02452232]\n",
            "[0.8226706  0.17732944]\n",
            "[0.9760271  0.02397294]\n",
            "[0.0207737  0.97922635]\n",
            "[0.97611105 0.0238889 ]\n",
            "[0.9761263  0.02387366]\n",
            "[0.97173053 0.02826952]\n",
            "[0.9384567  0.06154331]\n",
            "[0.85108054 0.14891963]\n",
            "[0.97604245 0.02395764]\n",
            "[0.01185849 0.98814154]\n",
            "[0.96171534 0.0382847 ]\n",
            "[0.9760194 0.0239806]\n",
            "[0.9435679  0.05643217]\n",
            "[0.97404075 0.02595928]\n",
            "[0.01185849 0.98814154]\n",
            "[0.07420922 0.9257907 ]\n",
            "[0.95881313 0.04118685]\n",
            "[0.9760575  0.02394235]\n",
            "[0.03008241 0.96991765]\n",
            "[0.9083374  0.09166252]\n",
            "[0.05686053 0.9431395 ]\n",
            "[0.02500949 0.9749905 ]\n",
            "[0.85108054 0.14891963]\n",
            "[0.9760575  0.02394235]\n",
            "[0.97610337 0.02389652]\n",
            "[0.01302428 0.98697567]\n",
            "[0.01724264 0.9827573 ]\n",
            "[0.03008241 0.96991765]\n",
            "[0.06794389 0.93205607]\n",
            "[0.03297994 0.9670201 ]\n",
            "[0.10498349 0.89501643]\n",
            "[0.12462534 0.87537456]\n",
            "[0.4152179 0.5847821]\n",
            "[0.0207737  0.97922635]\n",
            "[0.9760271  0.02397294]\n",
            "[0.11443797 0.88556206]\n",
            "[0.01570528 0.9842946 ]\n",
            "[0.85108054 0.14891963]\n",
            "[0.05197766 0.9480223 ]\n",
            "[0.23565485 0.76434517]\n",
            "[0.9760424  0.02395764]\n",
            "[0.01724264 0.9827573 ]\n",
            "[0.14733715 0.85266286]\n",
            "[0.93254644 0.0674535 ]\n",
            "[0.7535134  0.24648654]\n",
            "[0.9761263  0.02387366]\n",
            "[0.03008241 0.96991765]\n",
            "[0.9679746  0.03202535]\n",
            "[0.9760652 0.0239347]\n",
            "[0.9480444  0.05195563]\n",
            "[0.97608054 0.02391943]\n",
            "[0.9435679  0.05643217]\n",
            "[0.01892758 0.9810724 ]\n",
            "[0.97605    0.02394999]\n",
            "[0.27526   0.7247401]\n",
            "[0.9384567  0.06154331]\n",
            "[0.97252196 0.02747807]\n",
            "[0.93254644 0.0674535 ]\n",
            "[0.9261135  0.07388657]\n",
            "[0.9754777  0.02452232]\n",
            "[0.03960393 0.96039605]\n",
            "[0.97611105 0.0238889 ]\n",
            "[0.03297994 0.96702003]\n",
            "[0.46657914 0.5334208 ]\n",
            "[0.4152179 0.5847821]\n",
            "[0.27526   0.7247401]\n",
            "[0.01724264 0.9827573 ]\n",
            "[0.06217197 0.93782794]\n",
            "[0.07420922 0.9257907 ]\n",
            "[0.11443797 0.88556206]\n",
            "[0.96171534 0.0382847 ]\n",
            "[0.08835743 0.9116426 ]\n",
            "[0.36563474 0.6343653 ]\n",
            "[0.9261135  0.07388657]\n",
            "[0.11443797 0.88556206]\n",
            "[0.85108054 0.14891963]\n",
            "[0.93254644 0.0674535 ]\n",
            "[0.9760806  0.02391943]\n",
            "[0.16885583 0.83114403]\n",
            "[0.9740407  0.02595927]\n",
            "[0.02500949 0.97499055]\n",
            "[0.9554852  0.04451472]\n",
            "[0.9760652 0.0239347]\n",
            "[0.12462534 0.87537456]\n",
            "[0.23565485 0.76434517]\n",
            "[0.97605    0.02394999]\n",
            "[0.94804436 0.05195563]\n",
            "[0.01892758 0.9810724 ]\n",
            "[0.16885583 0.83114403]\n",
            "[0.0207737  0.97922635]\n",
            "[0.9660294  0.03397056]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each element in the predictions list is itself a list of length 2. The sum of the two values in each list is 1. The reason for this is because the two columns contain probabilities for each possible output: experienced side effects and did not experience side effects. Each element in the predictions list is a probability distribution over all possible outputs.\n",
        "\n",
        "The first column contains the probability for each patient not experiencing side effects, which is represented by a 0. The second column contains the probability for each patient experiencing side effects, which is represented by a 1.\n",
        "\n",
        "We can also look only at the most probable prediction."
      ],
      "metadata": {
        "id": "kzuL0RgfmAXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "for i in rounded_predictions:\n",
        "    print(i)\n",
        "\n",
        "    # Output    0 - this patient likely has no side effects\n",
        "     #         1 -  this patient likely has Create A Confusion Matrix For Neural Network Predictionsside effects\n",
        "     #         1\n",
        "      #        1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAUMbBPamCc1",
        "outputId": "6a151a3a-dbb2-4de5-b469-49920a243cd0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the printed prediction results, we can observe the underlying predictions from the model, however, we cannot judge how accurate these predictions are just by looking at the predicted output.\n",
        "\n",
        "If we have corresponding labels for the test set, (for which, in this case, we do), then we can compare these true labels to the predicted labels to judge the accuracy of the model's evaluations. We'll see how to visualize this using a tool called a confusion matrix in the next episode."
      ],
      "metadata": {
        "id": "PTYov01bmGKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create A Confusion Matrix For Neural Network Predictions\n",
        "\n",
        "\n",
        "In this episode, we'll demonstrate how to create a confusion matrix, which will aid us in being able to visually observe how well a neural network is predicting during inference.\n",
        "\n",
        "We'll continue working with the predictions we obtained from the tf.keras.Sequential model in the last episode.\n",
        "\n",
        "With a confusion matrix, we'll be able to visually observe how well the model predicts on test data.\n",
        "\n",
        "Let's jump into the code for how this is done.\n",
        "\n",
        "# Plotting A Confusion Matrix\n",
        "First, we import all the required libraries we'll be working with."
      ],
      "metadata": {
        "id": "L140VZ0fpSG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Ryvzvw6uo0mm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix we'll be plotting comes from scikit-learn.\n",
        "\n",
        "We then create the confusion matrix and assign it to the variable cm. T"
      ],
      "metadata": {
        "id": "mo2HDb0RqiJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true=test_labels, y_pred=rounded_predictions)"
      ],
      "metadata": {
        "id": "W8K528V_qiym"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To the confusion matrix, we pass in the true labels test_labels as well as the network's predicted labels rounded_predictions for the test set.\n",
        "\n",
        "Below, we have a function called plot_confusion_matrix() that came directly from scikit-learn's website. This is code that they provide in order to plot the confusion matrix.\n",
        "\n"
      ],
      "metadata": {
        "id": "zNOp_IjQqxE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "tlAq0N9Vqx6T"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we define the labels for the confusion matrix. In our case, the labels are titled “no side effects” and “had side effects.”"
      ],
      "metadata": {
        "id": "_jK2q0nkq8ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm_plot_labels = ['no_side_effects','had_side_effects']"
      ],
      "metadata": {
        "id": "P1eijiaFq9he"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we plot the confusion matrix by using the plot_confusion_matrix() function we just discussed. To this function, we pass in the confusion matrix cm and the labels cm_plot_labels, as well as a title for the confusion matrix."
      ],
      "metadata": {
        "id": "CYCiXBpfq_rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "0hR6Ot6TrC1F",
        "outputId": "d1c49338-1fd0-4f88-cea3-a96f792b25ee"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[195  15]\n",
            " [ 10 200]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading A Confusion Matrix\n",
        "Looking at the plot of the confusion matrix, we have the predicted labels on the x-axis and the true labels on the y-axis. The blue cells running from the top left to bottom right contain the number of samples that the model accurately predicted. The white cells contain the number of samples that were incorrectly predicted.\n",
        "\n",
        "There are 420 total samples in the test set. Looking at the confusion matrix, we can see that the model accurately predicted 391 out of 420 total samples. The model incorrectly predicted 29 out of the 420.\n",
        "\n",
        "For the samples the model got correct, we can see that it accurately predicted that the patients would experience no side effects 191 times. It incorrectly predicted that the patient would have no side effects 10 times when the patient did actually experience side effects.\n",
        "\n",
        "On the other side, the model accurately predicted that the patient would experience side effects 200 times that the patient did indeed experience side effects. It incorrectly predicted that the patient would have side effects 19 times when the patient actually did not experience side effects.\n",
        "\n",
        "As you can see, this is a good way we can visually interpret how well the model is doing at its predictions and understand where it may need some work."
      ],
      "metadata": {
        "id": "KKKNUkwvrQQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save And Load A Model With TensorFlow's Keras API\n",
        "\n"
      ],
      "metadata": {
        "id": "uSTTFZX6sYpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving And Loading The Model In Its Entirety\n",
        "If we want to save a model at its current state after it was trained so that we could make use of it later, we can call the save() function on the model. To save(), we pass in the file path and name of the file we want to save the model to with an h5 extension."
      ],
      "metadata": {
        "id": "lUU5_x9wtWrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('models/medical_trial_model.h5')"
      ],
      "metadata": {
        "id": "fIVdY6n_taU4"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "Note, this function also allows for saving the model as a Tensorflow SavedModel as well if you'd prefer.\n",
        "\n",
        "This method of saving will save everything about the model – the architecture, the weights, the optimizer, the state of the optimizer, the learning rate, the loss, etc.\n",
        "\n",
        "Now that we have this model saved, we can load the model at a later time.\n",
        "\n",
        "To do so, we first import the load_model() function. Then, we can call the function to load the model by pointing to the saved model on disk.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zUHxVP4os0X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "new_model = load_model('models/medical_trial_model.h5')\n"
      ],
      "metadata": {
        "id": "uENoS0_Pti4S"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can verify that the loaded model has the same architecture and weights as the saved model by calling summary() and get_weights() on the model."
      ],
      "metadata": {
        "id": "5IhQzkC9tk0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.summary()\n",
        "\n",
        "# Model: \"sequential_1\"\n",
        "# _________________________________________________________________\n",
        "# Layer (type)                 Output Shape              Param #   \n",
        "# =================================================================\n",
        "# dense_1 (Dense)              (None, 16)                32        \n",
        "# _________________________________________________________________\n",
        "# dense_2 (Dense)              (None, 32)                544       \n",
        "# _________________________________________________________________\n",
        "# dense_3 (Dense)              (None, 2)                 66        \n",
        "# =================================================================\n",
        "# Total params: 642\n",
        "# Trainable params: 642\n",
        "# Non-trainable params: 0\n",
        "# _________________________________________________________________\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ4kyaFqs6CA",
        "outputId": "82335f41-fa8d-4ec0-86b3-1789d361c3d1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 16)                32        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also inspect attributes about the model, like the optimizer and loss by calling model.optimizer and model.loss on the loaded model and compare the results to the previously saved model.\n",
        "\n",
        "This is the most encompassing way to save and load a model."
      ],
      "metadata": {
        "id": "cRu7_i8Zs9EO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving And Loading Only The Architecture Of The Model\n",
        "There is another way we save only the architecture of the model. This will not save the model weights, configurations, optimizer, loss or anything else. This only saves the architecture of the model.\n",
        "\n",
        "We can do this by calling model.to_json(). This will save the architecture of the model as a JSON string. If we print out the string, we can see exactly what this looks like."
      ],
      "metadata": {
        "id": "Q1oLGWVPt9e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_string = model.to_json()\n",
        "json_string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "9ih_F8Lst_1t",
        "outputId": "01b24b8e-599a-442b-dfda-292763071a73"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_3_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"dtype\": \"float32\", \"batch_input_shape\": [null, 1], \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_4\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_5\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.11.0\", \"backend\": \"tensorflow\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have this saved, we can create a new model from it. First we'll import the needed model_from_json function, and then we can load the model architecture."
      ],
      "metadata": {
        "id": "qj8IeQx1uEL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "model_architecture = model_from_json(json_string)"
      ],
      "metadata": {
        "id": "uJHbbv0guFiS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By printing the summary of the model, we can verify that the new model has the same architecture of the model that was previously saved."
      ],
      "metadata": {
        "id": "su9tMJ8MuJRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_architecture.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5vOsi3TuKZ2",
        "outputId": "974ea39f-cfc5-4f3a-ea84-402fa1d562cd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 16)                32        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note, we can also use this same approach to saving and loading the model architecture to and from a YAML string. To do so, we use the functions to_yaml() and model_from_yaml() in the same fashion as we called the json functions."
      ],
      "metadata": {
        "id": "XedeJ-OWuOa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving And Loading The Weights Of The Model\n",
        "The last saving mechanism we'll discuss only saves the weights of the model.\n",
        "\n",
        "We can do this by calling model.save_weights() and passing in the path and file name to save the weights to with an h5 extension."
      ],
      "metadata": {
        "id": "8raFi1PPuQMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('models/my_model_weights.h5')"
      ],
      "metadata": {
        "id": "yRY366u9uSaz"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At a later point, we could then load the saved weights in to a new model, but the new model will need to have the same architecture as the old model before the weights can be saved."
      ],
      "metadata": {
        "id": "rg7niAY7uUXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([\n",
        "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=2, activation='softmax')\n",
        "])\n",
        "\n",
        "model2.load_weights('models/my_model_weights.h5')"
      ],
      "metadata": {
        "id": "yCs8QrIkuVtf"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've now seen how to save only the weights of a model and deploy those weights to a new model, how to save only the architecture and then deploy that architecture to a model, and how to save everything about a model and deploy it in its entirety at a later time. Each of these saving and loading mechanisms may come in useful in differing scenarios."
      ],
      "metadata": {
        "id": "Bok05TT4uXQs"
      }
    }
  ]
}