{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1we6Dxky4mnkloL2aVZNX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robsub/Keras/blob/main/Part_1_tf_Keras_deepliard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5w4wdU-gSDGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "1N1YY0YrFchX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HXWcekcnEfC9"
      },
      "outputs": [],
      "source": [
        "# create lists to hold samples and labels\n",
        "\n",
        "train_labels = []\n",
        "train_samples = []"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example data:\n",
        "\n",
        "- An experimental drug was tested on infivifuals from ages 13 to 100 in a clinical trial. \n",
        "\n",
        "- The trial had 2100 participants. Half were under 65 years old, half were under 65 years or older. \n",
        "\n",
        "- Around 95% of patients 65 or older experienced side effects. \n",
        "\n",
        "- Around 95% of patients under 65% experienced no side effects. "
      ],
      "metadata": {
        "id": "WHpqlDb_GzLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "fit(\n",
        "    x=None,\n",
        "    y=None,\n",
        "    batch_size=None,\n",
        "    epochs=1,\n",
        "    verbose='auto',\n",
        "    callbacks=None,\n",
        "    validation_split=0.0,\n",
        "    validation_data=None,\n",
        "    shuffle=True,\n",
        "    class_weight=None,\n",
        "    sample_weight=None,\n",
        "    initial_epoch=0,\n",
        "    steps_per_epoch=None,\n",
        "    validation_steps=None,\n",
        "    validation_batch_size=None,\n",
        "    validation_freq=1,\n",
        "    max_queue_size=10,\n",
        "    workers=1,\n",
        "    use_multiprocessing=False\n",
        ")\n",
        "\n",
        "Trains the model for a fixed number of epochs (iterations on a dataset)."
      ],
      "metadata": {
        "id": "TBks0D5Vl6w_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Sequential X and Y lets use a numpy array (y must match x format)\n",
        "\n",
        "\n",
        "for i in range(50):\n",
        "# 5% younger individuals who did exp side effects\n",
        "  random_younger = randint(13,64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(1) # 1 = side effects\n",
        "\n",
        "# 5% older individuals who did not exp side effects\n",
        "  random_older = randint(65,100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(0) # 0 = no side effects\n",
        "\n",
        "for i in range(1000):\n",
        "# 95% younger individuals who did not exp side effects\n",
        "  random_younger = randint(13,64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(0)\n",
        "\n",
        "# 95% older individuals who did exp side effects\n",
        "  random_older = randint(65,100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(1)\n",
        "\n"
      ],
      "metadata": {
        "id": "e-BRT8yJSDla"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_samples[:5]: # print first 5 only\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aPFDGIcp-Fk",
        "outputId": "2fe6feb6-308c-4868-ed5b-cecf80f30b44"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39\n",
            "64\n",
            "23\n",
            "58\n",
            "71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_labels[:5]:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F96u8wPGxUA",
        "outputId": "72e5f6c3-c23b-40e1-c276-09cae3c77e63"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LEts process the data to be piped into something the fit command expects (lets go with a numpy array)\n",
        "\n",
        "train_labels = np.array(train_labels) # This line is converting the train_labels list to a numpy array. Numpy is a numerical computing library for Python and numpy.array() is a function that creates a new numpy array from a given list.\n",
        "train_samples = np.array(train_samples) # This line is converting the train_samples list to a numpy array.\n",
        "train_labels,train_samples = shuffle(train_labels, train_samples) # This line is shuffling the two numpy arrays train_labels and train_samples together using the shuffle() function from the sklearn.utils module. This is a common technique used in machine learning to randomize the order of the training data so that the model does not learn any order-related biases. The function returns two shuffled arrays, which are then unpacked and assigned to the original variable names train_labels and train_samples.\n",
        "\n",
        "# Check the type of the variables after conversion\n",
        "print(type(train_labels))   # Output: <class 'numpy.ndarray'>\n",
        "print(type(train_samples))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1UNp78Fp3-s",
        "outputId": "6ed57c10-afaf-43fa-92d3-101a5ec445e5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is scaling the train_samples data to normalize and standardize it, which is a common technique used in machine learning to improve model performance.\n",
        "\n",
        "# The MinMaxScaler is a scaler object from the sklearn.preprocessing module that scales data to a specified range, which is [0,1] in this case. The feature_range parameter specifies the desired range.\n",
        "\n",
        "# train_samples is reshaped to a 2D numpy array using the reshape() function with -1 as the first parameter and 1 as the second parameter. This is necessary because the fit_transform() method of MinMaxScaler expects a 2D array as input.\n",
        "\n",
        "# The fit_transform() method of MinMaxScaler is then called on the reshaped train_samples data to fit the scaler to the data and transform it to the specified range. The resulting scaled data is assigned to the scaled_train_samples variable.\n",
        "\n",
        "# AKA minmax scaler object used to create feature_range, feature range is then used on next line to rescale data from current range which is 13 to 100 down to a scale of 0 to 1. and the last bit ((train_samples.reshape(-1,1))) is changing data from 1 dimensional to 2 dimensional which is what is expected by the fit function. \n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
      ],
      "metadata": {
        "id": "KEDPpaK7szXw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in scaled_train_samples[:5]:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySsJ5shCvrMy",
        "outputId": "10cf554a-f844-4b9d-d929-544dc75fc43a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.29885057]\n",
            "[0.5862069]\n",
            "[0.11494253]\n",
            "[0.51724138]\n",
            "[0.66666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple tf.keras Sequential Model"
      ],
      "metadata": {
        "id": "k-l_8CJ1yl84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf # to BUILD our first model\n",
        "from tensorflow import keras # to BUILD our first model\n",
        "from tensorflow.keras.models import Sequential # to BUILD our first model\n",
        "from tensorflow.keras.layers import Activation, Dense # to BUILD our first model\n",
        "from tensorflow.keras.optimizers import Adam # to TRAIN our first model\n",
        "from tensorflow.keras.metrics import categorical_crossentropy # to TRAIN our first model\n",
        "\n",
        "# tensorflow is an open-source software library for dataflow and differentiable programming across a range of tasks. It is commonly used for building deep learning models.\n",
        "# keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It is designed to enable fast experimentation with deep neural networks, and thus it is commonly used for building and training neural networks.\n",
        "# Sequential is a Keras class for creating a sequential neural network model.\n",
        "# Activation is a Keras class that specifies the activation function to be used in a neural network layer.\n",
        "# Dense is a Keras class that specifies a fully connected neural network layer.\n",
        "# Adam is a Keras class that specifies the optimizer used for training a neural network model.\n",
        "# categorical_crossentropy is a Keras metric used to calculate the loss of a classification model during training.\n",
        "# You will use these libraries and classes to define, compile, and train your neural network model for your specific machine learning task.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Je6eSvCryq84"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}